# AIRD í’ˆì§ˆì§„ë‹¨ ë¦¬í¬íŠ¸ ê°€ì´ë“œ

## ğŸ“‹ ë¬¸ì„œ ì •ë³´
- **ë²„ì „**: 1.0
- **ì‘ì„±ì¼**: 2025-11-28
- **ëŒ€ìƒ**: ë°ì´í„° ê´€ë¦¬ì, ë¶„ì„ê°€, ì •ì±… ë‹´ë‹¹ì

---

## ğŸ¯ í’ˆì§ˆì§„ë‹¨ì˜ ì¤‘ìš”ì„±

### ì™œ ë°ì´í„° í’ˆì§ˆì§„ë‹¨ì´ í•„ìš”í•œê°€?

**"Garbage In, Garbage Out"**

AI/ML ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ì…ë ¥ ë°ì´í„°ì˜ í’ˆì§ˆì— ì§ì ‘ì ìœ¼ë¡œ ì˜ì¡´í•©ë‹ˆë‹¤.  
ì•„ë¬´ë¦¬ ë›°ì–´ë‚œ ì•Œê³ ë¦¬ì¦˜ì´ë¼ë„ í’ˆì§ˆì´ ë‚®ì€ ë°ì´í„°ë¡œëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

### í’ˆì§ˆì§„ë‹¨ì˜ íš¨ê³¼

1. **ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ**: í’ˆì§ˆ ë†’ì€ ë°ì´í„° â†’ ì •í™•í•œ ì˜ˆì¸¡
2. **ë¹„ìš© ì ˆê°**: ì‚¬ì „ ì˜¤ë¥˜ ì œê±° â†’ ì¬ì‘ì—… ë°©ì§€
3. **ì‹ ë¢°ë„ ì œê³ **: ê²€ì¦ëœ ë°ì´í„° â†’ ì˜ì‚¬ê²°ì • ì‹ ë¢°
4. **ê·œì • ì¤€ìˆ˜**: ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ê¸°ì¤€ ì¶©ì¡±

---

## ğŸ“Š 5ëŒ€ í’ˆì§ˆ ì°¨ì›

### 1. ì™„ì „ì„± (Completeness)

**ì •ì˜**: ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì™„ì „í•œê°€?

**í‰ê°€ í•­ëª©**:
- ê²°ì¸¡ì¹˜ ë¹„ìœ¨
- í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€
- ë¹ˆ ë¬¸ìì—´ ê²€ì‚¬

**í‰ê°€ ê¸°ì¤€**:
| ì ìˆ˜ | ë“±ê¸‰ | ê²°ì¸¡ì¹˜ ë¹„ìœ¨ | í‰ê°€ |
|------|------|------------|------|
| 90-100 | A | 0-5% | ìš°ìˆ˜ |
| 80-89 | B | 5-10% | ì–‘í˜¸ |
| 70-79 | C | 10-20% | ë³´í†µ |
| 60-69 | D | 20-30% | ë¯¸í¡ |
| 0-59 | F | 30%+ | ë¶ˆëŸ‰ |

**ê°œì„  ë°©ë²•**:
```python
# ê²°ì¸¡ì¹˜ ë³´ì™„ ì˜ˆì‹œ
df['ì œì¡°ì‹œì„¤ë©´ì '].fillna(df['ì œì¡°ì‹œì„¤ë©´ì '].median(), inplace=True)

# í•„ìˆ˜ ì»¬ëŸ¼ ì¶”ê°€
if 'ê³µì¥ê´€ë¦¬ë²ˆí˜¸' not in df.columns:
    df['ê³µì¥ê´€ë¦¬ë²ˆí˜¸'] = df.index.astype(str)
```

---

### 2. ì •í™•ì„± (Accuracy)

**ì •ì˜**: ë°ì´í„°ê°€ í˜„ì‹¤ì„ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ë°˜ì˜í•˜ëŠ”ê°€?

**í‰ê°€ í•­ëª©**:
- ë‚ ì§œ í˜•ì‹ ì •í™•ì„±
- ìˆ«ì ë°ì´í„° ìœ íš¨ì„± (ìŒìˆ˜, ì´ìƒì¹˜)
- ì£¼ì†Œ í˜•ì‹ ê²€ì¦
- ì½”ë“œ ì²´ê³„ ì¤€ìˆ˜

**í‰ê°€ ê¸°ì¤€**:
| ì ìˆ˜ | ì˜¤ë¥˜ìœ¨ | í‰ê°€ |
|------|--------|------|
| 90-100 | 0-2% | ìš°ìˆ˜ |
| 80-89 | 2-5% | ì–‘í˜¸ |
| 70-79 | 5-10% | ë³´í†µ |
| 60-69 | 10-15% | ë¯¸í¡ |
| 0-59 | 15%+ | ë¶ˆëŸ‰ |

**ê°œì„  ë°©ë²•**:
```python
# ë‚ ì§œ í˜•ì‹ í‘œì¤€í™”
df['ìµœì´ˆìŠ¹ì¸ì¼'] = pd.to_datetime(
    df['ìµœì´ˆìŠ¹ì¸ì¼'], 
    format='%Y%m%d', 
    errors='coerce'
)

# ìŒìˆ˜ ì œê±°
df.loc[df['ì œì¡°ì‹œì„¤ë©´ì '] < 0, 'ì œì¡°ì‹œì„¤ë©´ì '] = np.nan

# ì£¼ì†Œ ì •ì œ
df['ê³µì¥ì£¼ì†Œ'] = df['ê³µì¥ì£¼ì†Œ'].str.strip()
df['ê³µì¥ì£¼ì†Œ'] = df['ê³µì¥ì£¼ì†Œ'].str.replace(r'\s+', ' ', regex=True)
```

---

### 3. ì¼ê´€ì„± (Consistency)

**ì •ì˜**: ë°ì´í„°ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ì¼ê´€ì„± ìˆëŠ”ê°€?

**í‰ê°€ í•­ëª©**:
- ì¤‘ë³µ ë ˆì½”ë“œ
- ë°ì´í„° í˜•ì‹ í†µì¼ì„±
- ë²”ì£¼í˜• ê°’ í‘œì¤€í™”
- Cross-field ê²€ì¦

**í‰ê°€ ê¸°ì¤€**:
| ì ìˆ˜ | ì¤‘ë³µë¥  | í‰ê°€ |
|------|--------|------|
| 90-100 | 0-1% | ìš°ìˆ˜ |
| 80-89 | 1-3% | ì–‘í˜¸ |
| 70-79 | 3-5% | ë³´í†µ |
| 60-69 | 5-10% | ë¯¸í¡ |
| 0-59 | 10%+ | ë¶ˆëŸ‰ |

**ê°œì„  ë°©ë²•**:
```python
# ì¤‘ë³µ ì œê±°
df = df.drop_duplicates(subset=['ê³µì¥ê´€ë¦¬ë²ˆí˜¸'], keep='first')

# ë²”ì£¼í˜• ê°’ í‘œì¤€í™”
industry_mapping = {
    'ì œì¡°ì—…': 'ì œì¡°',
    'ì œ ì¡°': 'ì œì¡°',
    'è£½é€ ': 'ì œì¡°'
}
df['ì—…ì¢…ëª…'] = df['ì—…ì¢…ëª…'].replace(industry_mapping)

# Cross-field ê²€ì¦
# ì¢…ì—…ì›í•©ê³„ = ë‚¨ì + ì—¬ì + ì™¸êµ­ì¸ë‚¨ì + ì™¸êµ­ì¸ì—¬ì
employee_sum = (df['ë‚¨ìì¢…ì—…ì›'] + df['ì—¬ìì¢…ì—…ì›'] + 
                df['ì™¸êµ­ì¸ë‚¨ìì¢…ì—…ì›'] + df['ì™¸êµ­ì¸ì—¬ìì¢…ì—…ì›'])
df.loc[employee_sum != df['ì¢…ì—…ì›í•©ê³„'], 'ì¢…ì—…ì›í•©ê³„'] = employee_sum
```

---

### 4. ì ì‹œì„± (Timeliness)

**ì •ì˜**: ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ìµœì‹ ì¸ê°€?

**í‰ê°€ í•­ëª©**:
- ë°ì´í„° ìˆ˜ì§‘ ì‹œì 
- ìµœê·¼ ê°±ì‹  ë¹„ìœ¨
- ë°ì´í„° ì‹ ì„ ë„

**í‰ê°€ ê¸°ì¤€**:
| ì ìˆ˜ | ìµœì‹  ë°ì´í„° ë¹„ìœ¨ | í‰ê°€ |
|------|-----------------|------|
| 90-100 | 80%+ (ìµœê·¼ 1ë…„) | ìš°ìˆ˜ |
| 80-89 | 60-80% | ì–‘í˜¸ |
| 70-79 | 40-60% | ë³´í†µ |
| 60-69 | 20-40% | ë¯¸í¡ |
| 0-59 | 0-20% | ë¶ˆëŸ‰ |

**ê°œì„  ë°©ë²•**:
```python
# ìµœì‹  ë°ì´í„° ìš°ì„  ì‚¬ìš©
current_year = datetime.now().year
df['data_age'] = current_year - pd.to_datetime(df['ë“±ë¡ì¼']).dt.year

# ì˜¤ë˜ëœ ë°ì´í„° í•„í„°ë§ (5ë…„ ì´ìƒ)
df_recent = df[df['data_age'] <= 5]

# ì •ê¸° ê°±ì‹  í”„ë¡œì„¸ìŠ¤ ìˆ˜ë¦½
# - ë¶„ê¸°ë³„: ì¤‘ìš” ë°ì´í„°
# - ë°˜ê¸°ë³„: ì¼ë°˜ ë°ì´í„°
# - ì—°ê°„: ì°¸ê³  ë°ì´í„°
```

---

### 5. ìœ íš¨ì„± (Validity)

**ì •ì˜**: ë°ì´í„°ê°€ ì •ì˜ëœ ê·œì¹™ì„ ì–¼ë§ˆë‚˜ ì¤€ìˆ˜í•˜ëŠ”ê°€?

**í‰ê°€ í•­ëª©**:
- ê°’ì˜ ìœ íš¨ ë²”ìœ„
- ë…¼ë¦¬ì  ê´€ê³„ ê²€ì¦
- ì°¸ì¡° ë¬´ê²°ì„±

**í‰ê°€ ê¸°ì¤€**:
| ì ìˆ˜ | ìœ íš¨ì„± ìœ„ë°˜ | í‰ê°€ |
|------|------------|------|
| 90-100 | 0-2% | ìš°ìˆ˜ |
| 80-89 | 2-5% | ì–‘í˜¸ |
| 70-79 | 5-10% | ë³´í†µ |
| 60-69 | 10-20% | ë¯¸í¡ |
| 0-59 | 20%+ | ë¶ˆëŸ‰ |

**ê°œì„  ë°©ë²•**:
```python
# ê°’ ë²”ìœ„ ê²€ì¦
valid_ages = (df['ê³µì¥ì—°ë ¹'] >= 0) & (df['ê³µì¥ì—°ë ¹'] <= 100)
df.loc[~valid_ages, 'ê³µì¥ì—°ë ¹'] = np.nan

# ë…¼ë¦¬ì  ê´€ê³„ ê²€ì¦
# ì œì¡°ì‹œì„¤ë©´ì  + ë¶€ëŒ€ì‹œì„¤ë©´ì  â‰¤ ê±´ì¶•ë©´ì 
facility_sum = df['ì œì¡°ì‹œì„¤ë©´ì '] + df['ë¶€ëŒ€ì‹œì„¤ë©´ì ']
invalid_area = facility_sum > df['ê±´ì¶•ë©´ì '] * 1.1  # 10% ì˜¤ì°¨ í—ˆìš©
df.loc[invalid_area, ['ì œì¡°ì‹œì„¤ë©´ì ', 'ë¶€ëŒ€ì‹œì„¤ë©´ì ']] = np.nan
```

---

## ğŸ“‹ í’ˆì§ˆì§„ë‹¨ í”„ë¡œì„¸ìŠ¤

### Step 1: ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰

```python
import pandas as pd
import numpy as np

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('seoul_factory_registry_2025_v1.csv')

# ê¸°ë³¸ ì •ë³´ í™•ì¸
print(f"í–‰ ìˆ˜: {len(df):,}")
print(f"ì—´ ìˆ˜: {len(df.columns)}")
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage().sum() / 1024**2:.2f} MB")

# ë°ì´í„° íƒ€ì…
print(df.dtypes.value_counts())
```

### Step 2: ìë™ í’ˆì§ˆì§„ë‹¨ ì‹¤í–‰

```python
# AIRD í’ˆì§ˆì§„ë‹¨ ë…¸íŠ¸ë¶ ì‹¤í–‰
jupyter notebook aird_quality_diagnosis.ipynb
```

### Step 3: ë¦¬í¬íŠ¸ ë¶„ì„

í’ˆì§ˆì§„ë‹¨ ì‹¤í–‰ í›„ ë‹¤ìŒì„ í™•ì¸:
1. ì¢…í•© í’ˆì§ˆ ì ìˆ˜
2. ì°¨ì›ë³„ ì„¸ë¶€ ì ìˆ˜
3. ë°œê²¬ëœ ë¬¸ì œì  ëª©ë¡
4. ê°œì„  ê¶Œê³ ì‚¬í•­

### Step 4: ê°œì„  ì¡°ì¹˜

ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ê°œì„ :
1. **High**: ì™„ì „ì„±, ì •í™•ì„± ë¬¸ì œ (ì¦‰ì‹œ ì¡°ì¹˜)
2. **Medium**: ì¼ê´€ì„±, ì ì‹œì„± ë¬¸ì œ (1ì£¼ì¼ ë‚´)
3. **Low**: ìœ íš¨ì„± ë¬¸ì œ (1ê°œì›” ë‚´)

### Step 5: ì¬ì§„ë‹¨

ê°œì„  í›„ ë‹¤ì‹œ í’ˆì§ˆì§„ë‹¨ ì‹¤í–‰í•˜ì—¬ íš¨ê³¼ í™•ì¸

---

## ğŸ“Š í’ˆì§ˆ ë¦¬í¬íŠ¸ í•´ì„

### ì¢…í•© ì ìˆ˜ë³„ ì¡°ì¹˜

#### 90-100ì  (Aë“±ê¸‰)
- **ìƒíƒœ**: ìš°ìˆ˜
- **ì¡°ì¹˜**: í˜„ì¬ í’ˆì§ˆ ìœ ì§€
- **ì£¼ê¸°**: ë¶„ê¸°ë³„ ì¬ì§„ë‹¨

#### 80-89ì  (Bë“±ê¸‰)
- **ìƒíƒœ**: ì–‘í˜¸
- **ì¡°ì¹˜**: ë‚®ì€ ì°¨ì› ê°œì„ 
- **ì£¼ê¸°**: ì›”ë³„ ì¬ì§„ë‹¨

#### 70-79ì  (Cë“±ê¸‰)
- **ìƒíƒœ**: ë³´í†µ
- **ì¡°ì¹˜**: ê°œì„  ê³„íš ìˆ˜ë¦½ ë° ì‹¤í–‰
- **ì£¼ê¸°**: ì£¼ë³„ ëª¨ë‹ˆí„°ë§

#### 60-69ì  (Dë“±ê¸‰)
- **ìƒíƒœ**: ë¯¸í¡
- **ì¡°ì¹˜**: ì¦‰ì‹œ ê°œì„  í•„ìš”
- **ì£¼ê¸°**: ì¼ë³„ ëª¨ë‹ˆí„°ë§

#### 0-59ì  (Fë“±ê¸‰)
- **ìƒíƒœ**: ë¶ˆëŸ‰
- **ì¡°ì¹˜**: ë°ì´í„° ì‚¬ìš© ë³´ë¥˜, ì „ë©´ ê°œì„ 
- **ì£¼ê¸°**: ì—°ì† ëª¨ë‹ˆí„°ë§

---

## ğŸ› ï¸ í’ˆì§ˆ ê°œì„  ë„êµ¬

### 1. ë°ì´í„° ì •ì œ ë„êµ¬

```python
class DataCleaner:
    """ë°ì´í„° ì •ì œ ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    def remove_duplicates(df, key_column):
        """ì¤‘ë³µ ì œê±°"""
        before = len(df)
        df = df.drop_duplicates(subset=[key_column], keep='first')
        after = len(df)
        print(f"ì¤‘ë³µ ì œê±°: {before - after}ê°œ")
        return df
    
    @staticmethod
    def standardize_dates(df, date_columns, format='%Y%m%d'):
        """ë‚ ì§œ í˜•ì‹ í‘œì¤€í™”"""
        for col in date_columns:
            df[col] = pd.to_datetime(df[col], format=format, errors='coerce')
        return df
    
    @staticmethod
    def remove_outliers(df, column, method='iqr', threshold=3):
        """ì´ìƒì¹˜ ì œê±°"""
        if method == 'iqr':
            Q1 = df[column].quantile(0.25)
            Q3 = df[column].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - threshold * IQR
            upper = Q3 + threshold * IQR
            df.loc[(df[column] < lower) | (df[column] > upper), column] = np.nan
        return df
```

### 2. í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ë„êµ¬

```python
class QualityMonitor:
    """í’ˆì§ˆ ì§€ì† ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self, df):
        self.df = df
        self.baseline_scores = {}
    
    def set_baseline(self):
        """ê¸°ì¤€ì„  ì„¤ì •"""
        self.baseline_scores = {
            'completeness': self._assess_completeness(),
            'accuracy': self._assess_accuracy(),
            'consistency': self._assess_consistency()
        }
    
    def check_degradation(self, df_new):
        """í’ˆì§ˆ ì €í•˜ í™•ì¸"""
        current_scores = {
            'completeness': self._assess_completeness(df_new),
            'accuracy': self._assess_accuracy(df_new),
            'consistency': self._assess_consistency(df_new)
        }
        
        alerts = []
        for dim, baseline in self.baseline_scores.items():
            current = current_scores[dim]
            if current < baseline - 5:  # 5ì  ì´ìƒ í•˜ë½
                alerts.append(f"{dim}: {baseline:.1f} â†’ {current:.1f} (âš ï¸)")
        
        return alerts
```

---

## ğŸ“ˆ í’ˆì§ˆ ê°œì„  ì‚¬ë¡€

### ì‚¬ë¡€ 1: ê²°ì¸¡ì¹˜ ë³´ì™„ (ì™„ì „ì„± ê°œì„ )

**Before**:
- ì œì¡°ì‹œì„¤ë©´ì  ê²°ì¸¡: 15%
- ì™„ì „ì„± ì ìˆ˜: 75ì 

**ì¡°ì¹˜**:
```python
# ë™ì¼ ìì¹˜êµ¬ ë‚´ ì¤‘ìœ„ê°’ìœ¼ë¡œ ëŒ€ì²´
for gu in df['ì‹œêµ°êµ¬ëª…'].unique():
    mask = (df['ì‹œêµ°êµ¬ëª…'] == gu) & df['ì œì¡°ì‹œì„¤ë©´ì '].isnull()
    median_area = df[df['ì‹œêµ°êµ¬ëª…'] == gu]['ì œì¡°ì‹œì„¤ë©´ì '].median()
    df.loc[mask, 'ì œì¡°ì‹œì„¤ë©´ì '] = median_area
```

**After**:
- ì œì¡°ì‹œì„¤ë©´ì  ê²°ì¸¡: 2%
- ì™„ì „ì„± ì ìˆ˜: 92ì  (+17ì )

---

### ì‚¬ë¡€ 2: ì¤‘ë³µ ì œê±° (ì¼ê´€ì„± ê°œì„ )

**Before**:
- ì¤‘ë³µ ë ˆì½”ë“œ: 5%
- ì¼ê´€ì„± ì ìˆ˜: 70ì 

**ì¡°ì¹˜**:
```python
# ê³µì¥ê´€ë¦¬ë²ˆí˜¸ ê¸°ì¤€ ì¤‘ë³µ ì œê±°
df = df.drop_duplicates(subset=['ê³µì¥ê´€ë¦¬ë²ˆí˜¸'], keep='first')

# ìœ ì‚¬ ì£¼ì†Œ ë³‘í•©
df['ì£¼ì†Œ_ì •ì œ'] = df['ê³µì¥ì£¼ì†Œ'].str.replace(r'\s+', '', regex=True)
df = df.drop_duplicates(subset=['ì£¼ì†Œ_ì •ì œ'], keep='first')
```

**After**:
- ì¤‘ë³µ ë ˆì½”ë“œ: 0.5%
- ì¼ê´€ì„± ì ìˆ˜: 95ì  (+25ì )

---

## ğŸ¯ í’ˆì§ˆ ëª©í‘œ ì„¤ì •

### ë‹¨ê³„ë³„ ëª©í‘œ

#### ë‹¨ê¸° (1ê°œì›”)
- ì™„ì „ì„±: 80ì  ì´ìƒ
- ì •í™•ì„±: 75ì  ì´ìƒ
- ì¤‘ë³µ ë ˆì½”ë“œ 5% ë¯¸ë§Œ

#### ì¤‘ê¸° (3ê°œì›”)
- ì™„ì „ì„±: 90ì  ì´ìƒ
- ì •í™•ì„±: 85ì  ì´ìƒ
- ì¼ê´€ì„±: 90ì  ì´ìƒ

#### ì¥ê¸° (6ê°œì›”)
- ëª¨ë“  ì°¨ì›: 90ì  ì´ìƒ
- ì¢…í•© ì ìˆ˜: 90ì  ì´ìƒ (Aë“±ê¸‰)

---

## ğŸ“š ì°¸ê³  ìë£Œ

### êµ­ì œ í‘œì¤€
- ISO 8000: ë°ì´í„° í’ˆì§ˆ í‘œì¤€
- ISO 25012: ë°ì´í„° í’ˆì§ˆ ëª¨ë¸
- DAMA-DMBOK: ë°ì´í„° ê´€ë¦¬ ì§€ì‹ ì²´ê³„

### ì¶”ì²œ ë„ì„œ
- "Data Quality: The Accuracy Dimension" - Jack E. Olson
- "ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ë¡ " - í•œêµ­ë°ì´í„°ì‚°ì—…ì§„í¥ì›

### ì˜¨ë¼ì¸ ìë£Œ
- [AIRD Pack GitHub](https://github.com/your-org/aird-pack)
- [ë°ì´í„° í’ˆì§ˆ ê°€ì´ë“œ](https://www.data.go.kr/quality)

---

## ğŸ’¡ Best Practices

### 1. ì •ê¸°ì  ì§„ë‹¨
- ì›”ë³„ ìë™ í’ˆì§ˆì§„ë‹¨ ì‹¤í–‰
- ë¶„ê¸°ë³„ ì‹¬ì¸µ ë¶„ì„
- ì—°ê°„ ì¢…í•© í‰ê°€

### 2. ë¬¸ì œ ì¶”ì 
- ë°œê²¬ëœ ë¬¸ì œ ì´ìŠˆ íŠ¸ë˜í‚¹
- ê°œì„  ì¡°ì¹˜ ë¬¸ì„œí™”
- íš¨ê³¼ ì¸¡ì •

### 3. í˜‘ì—…
- ë°ì´í„° ìƒì‚°ìì™€ ì†Œí†µ
- ì´í•´ê´€ê³„ì í”¼ë“œë°± ìˆ˜ë ´
- ê°œì„  ì‚¬í•­ ê³µìœ 

### 4. ìë™í™”
- í’ˆì§ˆ ì²´í¬ ìë™í™”
- ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•
- ëŒ€ì‹œë³´ë“œ ëª¨ë‹ˆí„°ë§

---

## ğŸ”§ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### Q1: í’ˆì§ˆ ì ìˆ˜ê°€ ë‚®ê²Œ ë‚˜ì™”ìŠµë‹ˆë‹¤
**A**: ì°¨ì›ë³„ ì„¸ë¶€ ì ìˆ˜ë¥¼ í™•ì¸í•˜ê³ , ê°€ì¥ ë‚®ì€ ì°¨ì›ë¶€í„° ê°œì„ í•˜ì„¸ìš”.

### Q2: ê²°ì¸¡ì¹˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤
**A**: 
1. í•„ìˆ˜ ì»¬ëŸ¼ì¸ì§€ í™•ì¸
2. í•„ìˆ˜ê°€ ì•„ë‹ˆë©´ ì œì™¸ ê³ ë ¤
3. í•„ìˆ˜ë©´ ë°ì´í„° ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ê°œì„ 

### Q3: ì¤‘ë³µ ë ˆì½”ë“œë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?
**A**:
1. í‚¤ ì»¬ëŸ¼ ê¸°ì¤€ ì¤‘ë³µ í™•ì¸
2. ìµœì‹  ë°ì´í„° ìš°ì„  keep
3. ë³‘í•© ê°€ëŠ¥í•˜ë©´ ë³‘í•©

### Q4: ì´ìƒì¹˜ë¥¼ ëª¨ë‘ ì œê±°í•´ì•¼ í•˜ë‚˜ìš”?
**A**: 
- ëª…ë°±í•œ ì˜¤ë¥˜ëŠ” ì œê±°
- ê·¹ë‹¨ê°’ì´ì§€ë§Œ ìœ íš¨í•œ ê°’ì€ ìœ ì§€
- ë„ë©”ì¸ ì „ë¬¸ê°€ì™€ ìƒì˜

---

## ğŸ“ ì§€ì›

### ê¸°ìˆ  ì§€ì›
- ì´ë©”ì¼: aird-support@example.com
- GitHub Issues
- ì›”ê°„ Q&A ì„¸ì…˜

### êµìœ¡ í”„ë¡œê·¸ë¨
- í’ˆì§ˆì§„ë‹¨ ê¸°ì´ˆ (1ì¼)
- í’ˆì§ˆ ê°œì„  ì‹¤ë¬´ (2ì¼)
- í’ˆì§ˆ ê´€ë¦¬ ê³ ê¸‰ (3ì¼)

---

**AIRD Quality Diagnosis v1.0**  
**ì‘ì„±ì¼**: 2025-11-28  
**ë¬¸ì˜**: aird-support@example.com
